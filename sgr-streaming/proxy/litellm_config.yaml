general_settings:
  disable_spend_logging: true
  master_key: dev-key
  telemetry: false
model_list:
- litellm_params:
    api_base: http://localhost:11434
    max_tokens: 12000
    model: ollama/Flaude
    stream: true
    temperature: 0.2
  model_name: sgr-Flaude
- litellm_params:
    api_base: http://localhost:11434
    max_tokens: 12000
    model: ollama/deepseek-r1
    stream: true
    temperature: 0.2
  model_name: sgr-deepseek-r1
- litellm_params:
    api_base: http://localhost:11434
    max_tokens: 12000
    model: ollama/deepseek-r1:14b
    stream: true
    temperature: 0.2
  model_name: sgr-deepseek-r1-14b
- litellm_params:
    api_base: http://localhost:11434
    max_tokens: 12000
    model: ollama/gemma3:12b
    stream: true
    temperature: 0.2
  model_name: sgr-gemma3-12b
- litellm_params:
    api_base: http://localhost:11434
    max_tokens: 12000
    model: ollama/gemma3:27b-it-qat
    stream: true
    temperature: 0.2
  model_name: sgr-gemma3-27b-it-qat
- litellm_params:
    api_base: http://localhost:11434
    max_tokens: 12000
    model: ollama/gpt-oss:20b
    stream: true
    temperature: 0.2
  model_name: sgr-gpt-oss-20b
- litellm_params:
    api_base: http://localhost:11434
    max_tokens: 12000
    model: ollama/llama3.1
    stream: true
    temperature: 0.2
  model_name: sgr-llama3.1
- litellm_params:
    api_base: http://localhost:11434
    max_tokens: 12000
    model: ollama/llama3.2
    stream: true
    temperature: 0.2
  model_name: sgr-llama3.2
- litellm_params:
    api_base: http://localhost:11434
    max_tokens: 12000
    model: ollama/llama3.2:3b
    stream: true
    temperature: 0.2
  model_name: sgr-llama3.2-3b
- litellm_params:
    api_base: http://localhost:11434
    max_tokens: 12000
    model: ollama/mistral
    stream: true
    temperature: 0.2
  model_name: sgr-mistral
- litellm_params:
    api_base: http://localhost:11434
    max_tokens: 12000
    model: ollama/phi
    stream: true
    temperature: 0.2
  model_name: sgr-phi
- litellm_params:
    api_base: http://localhost:11434
    max_tokens: 12000
    model: ollama/phi3
    stream: true
    temperature: 0.2
  model_name: sgr-phi3
- litellm_params:
    api_base: http://localhost:11434
    max_tokens: 12000
    model: ollama/qwen2.5
    stream: true
    temperature: 0.2
  model_name: sgr-qwen2.5
- litellm_params:
    api_base: http://localhost:11434
    max_tokens: 12000
    model: ollama/qwen2.5-coder-32k
    stream: true
    temperature: 0.2
  model_name: sgr-qwen2.5-coder-32k
- litellm_params:
    api_base: http://localhost:11434
    max_tokens: 12000
    model: ollama/qwen2.5-coder:7b
    stream: true
    temperature: 0.2
  model_name: sgr-qwen2.5-coder-7b
- litellm_params:
    api_base: http://localhost:11434
    max_tokens: 12000
    model: ollama/qwencodo64
    stream: true
    temperature: 0.2
  model_name: sgr-qwencodo64
- litellm_params:
    api_base: http://localhost:11434
    max_tokens: 12000
    model: ollama/sgr-deepseek
    stream: true
    temperature: 0.2
  model_name: sgr-deepseek
- litellm_params:
    api_base: http://localhost:11434
    max_tokens: 12000
    model: ollama/sgr-gemma
    stream: true
    temperature: 0.2
  model_name: sgr-gemma
- litellm_params:
    api_base: http://localhost:11434
    max_tokens: 12000
    model: ollama/sgr-llama
    stream: true
    temperature: 0.2
  model_name: sgr-llama
- litellm_params:
    api_base: http://localhost:11434
    max_tokens: 12000
    model: ollama/sgr-llama2
    stream: true
    temperature: 0.1
  model_name: sgr-llama2
router_settings:
  num_retries: 0
